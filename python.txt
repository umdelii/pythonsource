w3schools => 코딩연습사이트

java => 컴파일러 설치
        JDK 설치

node.js => js 실행 환경 제공

Python => 인터프리터 설치 
    but, 인터프리터만으로는 개발 불가
    => 데이터 분석 : pandas, matplotlib ...
    => 크롤링 : 웹사이트등을 돌아다니며 데이터를 수집하는 행위
              정적 페이지(동기식 페이지)
              동적 페이지 => 셀레니움

    개발 목적에 따라 환경을 다르게 만듬 => python 인터프리터 + 개발 목적에 맞는 환경 = 가상환경

    웹어플리케이션
    자바 - 스프링부트
    파이썬 - django, flask
     인공지능(머신러닝) - 사이킷런, 텐서플로, 파이토치, 케라스
     수치연산(배열, 행렬) - 넘파이(numpy)
     데이터분석 - 판다스(pandas)

*.py => 파이썬 파일 
*.ipynb 주피터 노트북 => python을 줄 단위로 실행시켜주는 편집기

기본 입력
주석 : ctrl + / 
출력 : print(내용)
셀 추가 : b(아래), a(위)
셀 삭제 : dd
코드 줄 번호 표시 : Shift + L
마크다운으로 변경 : m (python으로 : y)

파이썬 라이브러리 다운 받는 법 : pip install 패키지명
pip : 파이썬용 라이브러리 설치 / 관리 도구

주요 라이브러리
       openpyxl : excel 읽기 가능한 라이브러리
       requests : 크롤링하기 편한 라이브러리
              기본 urllib.request 모듈과 같은 역할
              자동으로 디코딩해줌, json 처리 편함
              get, post, put, delete 메소드 제공
              session 적용 가능
       fake-useragent : 브라우저가 크롤링하는것처럼 눈속임하는 라이브러리
              크롤링 시 봇(bot) 차단을 우회하기 위해 다양한 브라우저의 User-Agent를 무작위로 생성하여 헤더에 적용하는 도구
       BeautifulSoup : 파이썬에서 HTML 및 XML 파일의 구조를 분석(파싱)하고 원하는 데이터를 쉽게 추출(스크래핑)하기 위해 사용하는 라이브러리
       Selenium : 동적 크롤링 라이브러리 (자동 검색 등등)
       pandas : excel + sql의 느낌, 데이터분석 라이브러리
       numpy : 숫자(배열, 행렬) 계산해주는 라이브러리

크롤링(스크랩핑)
 웹 자료 수집 
        => html/css/js => 텍스트/태그
 robots.txt
        예. naver
        User-agent: * : 모든 크롤러
        Disallow: / : 사이트 전체 크롤링 금지
        Allow : /$ : /로 끝나는 주소만 허용
        Allow : /.well-known/privacy-sandbox-attestations.json : 해당 파일 허용
 requests + BeautifulSoup으로 정적 크롤링
 Selenium으로 동적 크롤링



        